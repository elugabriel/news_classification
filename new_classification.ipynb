{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b9cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"nigeria_news.csv\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b930905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36931436",
   "metadata": {},
   "source": [
    "## Associate Category names with numerical index and save it in new column CategoryId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_category = dataset['Category'].unique()\n",
    "target_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['CategoryId'] = dataset['Category'].factorize()[0]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3177a",
   "metadata": {},
   "source": [
    "# Show Category’s Name with respect to  Category ID\n",
    "Here you can show that news category’s name with respect to the following unique category ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecffad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category = dataset[['Category', 'CategoryId']].drop_duplicates().sort_values('CategoryId')\n",
    "category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdef87",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('Category').CategoryId.value_counts().plot(kind = \"bar\", color = [\"pink\", \"skyblue\", \"brown\", \"grey\", \"blue\"])\n",
    "plt.xlabel(\"Category of data\")\n",
    "plt.title(\"Visulaize numbers of Category of data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5,5))\n",
    "colors = [\"skyblue\"]\n",
    "business = dataset[dataset['CategoryId'] == 0 ]\n",
    "tech = dataset[dataset['CategoryId'] == 1 ]\n",
    "politics = dataset[dataset['CategoryId'] == 2]\n",
    "sport = dataset[dataset['CategoryId'] == 3]\n",
    "entertainment = dataset[dataset['CategoryId'] == 4]\n",
    "count = [business['CategoryId'].count(), tech['CategoryId'].count(), politics['CategoryId'].count(), sport['CategoryId'].count(), entertainment['CategoryId'].count()]\n",
    "pie = plt.pie(count, labels = ['business', 'tech', 'politics', 'sport', 'entertainment'],\n",
    "              autopct = \"%1.1f%%\",\n",
    "              shadow = True,\n",
    "              colors = colors,\n",
    "              startangle = 45,\n",
    "              explode = (0.05, 0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dadd3c",
   "metadata": {},
   "source": [
    "# Visualizing Category Related Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66381b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67179291",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "business = dataset[dataset['CategoryId'] == 0]\n",
    "\n",
    "business = business['Text']\n",
    "\n",
    "tech = dataset[dataset['CategoryId'] == 1]\n",
    "\n",
    "tech = tech['Text']\n",
    "\n",
    "politics = dataset[dataset['CategoryId'] == 2]\n",
    "\n",
    "politics = politics['Text']\n",
    "\n",
    "sport = dataset[dataset['CategoryId'] == 3]\n",
    "\n",
    "sport = sport['Text']\n",
    "\n",
    "entertainment = dataset[dataset['CategoryId'] == 4]\n",
    "\n",
    "entertainment = entertainment['Text']\n",
    "\n",
    "def wordcloud_draw(dataset, color = 'white'):\n",
    "    words = ' '.join(dataset)\n",
    "\n",
    "    cleaned_word = ' '.join([word for word in words.split()if (word != 'news' and word != 'text')])\n",
    "\n",
    "    wordcloud = WordCloud(stopwords = stop,\n",
    "                      background_color = 'white',\n",
    "                      width = 2500, height = 2500).generate(cleaned_word)\n",
    "\n",
    "    plt.figure(1, figsize = (10,7))\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc40fd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"business related words:\")\n",
    "\n",
    "wordcloud_draw(business, 'white')\n",
    "\n",
    "print(\"tech related words:\")\n",
    "\n",
    "wordcloud_draw(tech, 'white')\n",
    "\n",
    "print(\"politics related words:\")\n",
    "\n",
    "wordcloud_draw(politics, 'white')\n",
    "\n",
    "print(\"sport related words:\")\n",
    "\n",
    "wordcloud_draw(sport, 'white')\n",
    "\n",
    "print(\"entertainment related words:\")\n",
    "\n",
    "wordcloud_draw(entertainment, 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b1474",
   "metadata": {},
   "source": [
    "# Show Text Column of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc031433",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[\"Text\"]\n",
    "text.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = dataset['Category']\n",
    "category.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65dcd1",
   "metadata": {},
   "source": [
    "## Remove All Tags, special Character and convert everything to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d75c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "  remove = re.compile(r'')\n",
    "  return re.sub(remove, '', text)\n",
    "dataset['Text'] = dataset['Text'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f156cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "dataset['Text'] = dataset['Text'].apply(special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower(text):\n",
    "   return text.lower()\n",
    "dataset['Text'] = dataset['Text'].apply(convert_lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb47bc",
   "metadata": {},
   "source": [
    "### Remove all Stopwords, Lemmatizing the Words and Declared Dependent and Independent Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd215de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return [x for x in words if x not in stop_words]\n",
    "dataset['Text'] = dataset['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_word(text):\n",
    "  wordnet = WordNetLemmatizer()\n",
    "  return \" \".join([wordnet.lemmatize(word) for word in text])\n",
    "dataset['Text'] = dataset['Text'].apply(lemmatize_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['Text']\n",
    "y = dataset['CategoryId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6414f",
   "metadata": {},
   "source": [
    "## Create and Fit Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "x = np.array(dataset.iloc[:,0].values)\n",
    "y = np.array(dataset.CategoryId.values)\n",
    "cv = CountVectorizer(max_features = 5000)\n",
    "x = cv.fit_transform(dataset.Text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f648814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv, open(\"countvectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X.shape = \",x.shape)\n",
    "print(\"y.shape = \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3fad9",
   "metadata": {},
   "source": [
    "## Train Test and Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996728fa",
   "metadata": {},
   "source": [
    "## Create, Fit and Predict all Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ebc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0).fit(x_train, y_train)\n",
    "model\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b737111",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = cv.transform(['Hour ago, I contemplated retirement for a lot of reasons. I felt like people were not sensitive enough to my injuries. I felt like a lot of people were backed, why not me? I have done no less. I have won a lot of games for the team, and I am not feeling backed, said Ashwin'])\n",
    "yy = model.predict(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ffb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of model and accuracy dicts\n",
    "perform_list = [ ]\n",
    "\n",
    "def run_model(model_name, est_c, est_pnlty):\n",
    "    mdl=''\n",
    "\n",
    "    if model_name == 'Logistic Regression':\n",
    "        mdl = LogisticRegression()\n",
    "\n",
    "    elif model_name == 'Random Forest':\n",
    "\n",
    "        mdl = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0)\n",
    "\n",
    "    elif model_name == 'Multinomial Naive Bayes':\n",
    "\n",
    "        mdl = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "\n",
    "    elif model_name == 'Support Vector Classifer':\n",
    "\n",
    "        mdl = SVC()\n",
    "\n",
    "    elif model_name == 'Decision Tree Classifier':\n",
    "        mdl = DecisionTreeClassifier()\n",
    "\n",
    "    elif model_name == 'K Nearest Neighbour':\n",
    "\n",
    "        mdl = KNeighborsClassifier(n_neighbors=10 , metric= 'minkowski' , p = 4)\n",
    "\n",
    "    elif model_name == 'Gaussian Naive Bayes':\n",
    "\n",
    "        mdl = GaussianNB()\n",
    "\n",
    "    oneVsRest = OneVsRestClassifier(mdl)\n",
    "\n",
    "    oneVsRest.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = oneVsRest.predict(x_test)\n",
    "    # Performance metrics\n",
    "\n",
    "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "\n",
    "    # Get precision, recall, f1 scores\n",
    "\n",
    "    precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "\n",
    "    print(f'Test Accuracy Score of Basic {model_name}: % {accuracy}')\n",
    "\n",
    "    print(f'Precision : {precision}')\n",
    "\n",
    "    print(f'Recall : {recall}')\n",
    "\n",
    "    print(f'F1-score : {f1score}')\n",
    "\n",
    "    # Add performance parameters to list\n",
    "\n",
    "    perform_list.append(dict([\n",
    "\n",
    "    ('Model', model_name),\n",
    "\n",
    "    ('Test Accuracy', round(accuracy, 2)),\n",
    "\n",
    "    ('Precision', round(precision, 2)),\n",
    "\n",
    "    ('Recall', round(recall, 2)),\n",
    "\n",
    "    ('F1', round(f1score, 2))\n",
    "\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166099bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_model('Logistic Regression', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('Random Forest', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('Multinomial Naive Bayes', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('Support Vector Classifer', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('Decision Tree Classifier', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('K Nearest Neighbour', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")\n",
    "run_model('Gaussian Naive Bayes', est_c=None, est_pnlty=None)\n",
    "print(\"========================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df546fd",
   "metadata": {},
   "source": [
    "## Create Dataframe of Model, Accuracy, Precision, Recall, and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb113fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame(data=perform_list)\n",
    "model_performance = model_performance[['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1']]\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Model to Perform Accuracy Score\n",
    "model = model_performance[\"Model\"]\n",
    "max_value = model_performance[\"Test Accuracy\"].max()\n",
    "print(\"The best accuracy of model is\", max_value,\"from Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = cv.transform(['Hour ago, I contemplated retirement for a lot of reasons. I felt like people were not sensitive enough to my injuries. I felt like a lot of people were backed, why not me? I have done no less. I have won a lot of games for the team, and I am not feeling backed, said Ashwin'])\n",
    "yy = classifier.predict(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86821467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
